{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdavistr-cmu/Davis-Troller_DSPN_S25/blob/main/ex11_the_beauty_of_knn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CWP61pr9u1p"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CoAxLab/Data-Explorations/blob/main/book/exercises/the-beauty-of-knn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Fpqv6H_cZA"
      },
      "source": [
        "# Exercise 11: The beauty of kNN\n",
        "\n",
        "In this exercise, you'll gain practice working with kNN. We'll use the [diamonds](https://ggplot2.tidyverse.org/reference/diamonds.html) dataset, which comes as part of `ggplot2`. This dataset provides information on the quality and price of 50,000 diamonds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is-1Gkl6_cZC"
      },
      "source": [
        "## 1. Data, Plotting, and Train/Test Sets (2 pts)\n",
        "-----\n",
        "* Load the the `class` and `tidyverse` packages.\n",
        "* Assign the `diamonds` data set to a simpler name. Then, create a new variable `price_bin` that splits the `price` variable into a binary variable, where 1 indicates that the diamond costs greater than the mean price, and 0 indicates that the diamond costs less than the mean price. Set `price_bin` to be a factor. (*Hint: use the if_else() function*)\n",
        "* Select just the `carat`, `depth`, `table`, `x`, `y`, and your new `price_bin` variables\n",
        "* Print the first few lines of the data set\n",
        "* Print the dimensions of the data set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "076b5Q2i_cZC",
        "scrolled": false,
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "library(class)\n",
        "library(tidyverse)\n",
        "\n",
        "d <- diamonds\n",
        "d <- d %>%\n",
        "  mutate(price_bin = if_else(price > mean(price), 1, 0),\n",
        "         price_bin = factor(price_bin))\n",
        "d <- d %>%\n",
        "  select(carat, depth, table, x, y, price_bin)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE--UOxM_cZD"
      },
      "source": [
        "### Plot\n",
        "Create a scatterplot of the link between `carat` and `depth`, and use the `color` aesthetics mapping to differentiate between diamonds that cost above versus below the mean price."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZQl5C9H_cZD",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# INSERT CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-K6NEON_cZD"
      },
      "source": [
        "Based on the above scatterplot, how do you think kNN will perform using only these two variables to predict diabetes diagnosis? Which variable, carat or depth, gives us the most information about which price class the diamond will belong to?\n",
        "> * *Write response here*\n",
        ">\n",
        "> *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT7O-CHO_cZE"
      },
      "source": [
        "### Test vs Train\n",
        "\n",
        "Before we run KNN on these data, we need to set aside a portion of the observations as our test set. Below, randomly divide the data such that 30% are allotted to the `test` set and the rest are allotted to the `train` set. Print the first few lines of each set, and print the dimensions of each set to double check your division of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oj3YcEP0_cZE",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "set.seed(2023)\n",
        "\n",
        "# INSERT CODE HERE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFtmRUBN_cZF"
      },
      "source": [
        "## 2: KNN (3 points)\n",
        "----\n",
        "Now, use the `knn()` function from the `class` library to predict `price_bin` from the `carat` and `depth`. Set `k = 3`.\n",
        "\n",
        "*Hint: Review the format required for the arguments of knn()*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pcL8AM9_cZG",
        "scrolled": true,
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "set.seed(2023)\n",
        "# INSERT CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXnTKbdi_cZG"
      },
      "source": [
        "Now, output a confusion matrix and calculate the test error to evaluate model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhwTYq9B_cZH",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# INSERT CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOQSLQ37_cZK"
      },
      "source": [
        "How did your model perform?\n",
        "> * Write your response here\n",
        ">\n",
        "> *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0lvEh3F_cZL"
      },
      "source": [
        "Let's try to improve our model by adding all of the other variables in our data set as predictors. Rerun your `knn()` below, keeping `k = 3`. Again, output a confusion matrix and error rate for your updated model fit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWsncoDP_cZL",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "set.seed(2023)\n",
        "# INSERT CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2Dyykaf_cZM"
      },
      "source": [
        "Did your model predictions improve?\n",
        "> * Write your response here\n",
        ">\n",
        "> *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYHprC4m_cZN"
      },
      "source": [
        "# 3: for loop (3 points)\n",
        "----\n",
        "\n",
        "So adding additional predictors didn't shift our error much. Let's see if adjusting `k` has a larger impact on model accuracy.\n",
        "\n",
        "Using your initial model above with just `carat` and `depth`, run a `for loop` that runs the same model 30 times, for `k = 1:30`.\n",
        "\n",
        "Output a data frame that has `k` and the overall `error` as columns.\n",
        "\n",
        "The structure of the output data frame and `for loop` are provided for you below. Note that your loop will take a minute or two to run because there are so many observations in the dataset. It may be helpful while you are writing and testing your loop to run it on a subset of the data with only a handful of rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-GAvxGH_cZN",
        "scrolled": false,
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# this is provided\n",
        "# setting up empty table to store for loop output\n",
        "output  <- data.frame(k = seq(1:30),\n",
        "                     error = rep(NA, 30))\n",
        "head(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "we6mzfCJ_cZN",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "for (k in seq(1:30)) {\n",
        "    knn_fits  <- # your knn function here\n",
        "\n",
        "    #overall error\n",
        "    conf_df  <- # data frame of test predictions versus actual test\n",
        "    output$error[k]  <- #calculate error from conf_df and add to your output dataframe\n",
        "\n",
        "}\n",
        "head(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ofk0jafy_cZN"
      },
      "source": [
        "Create a line plot of your `output` object using `ggplot`. Add a (non-linear) `geom_smooth` layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Oia_P98_cZN",
        "scrolled": false,
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# INSERT CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EG2gQhU0_cZO"
      },
      "source": [
        "Interpret your plot. What would you select as the best value of `k`? How much does this improve your test error?\n",
        "> * *Write your response here*\n",
        ">\n",
        "> *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5GYp8mt_cZO"
      },
      "source": [
        "# 4: Standardizing predictors (2)\n",
        "-----\n",
        "\n",
        "Because knn is based on distances between points, it is very sensitive to the scale of your variables. Looking at our predictor variables, we can see that `carat` and `depth` are orders of magnitude different in terms of scales. Maybe we can improve our fit even more by addressing this!\n",
        "\n",
        "Below, use the `scale()` function to standardize your predictors. (Note that you don't need to standardize `price_bin`.)\n",
        "\n",
        "Then, run your model a final time with your standardized predictors (just `carat` and `depth` still). Set `k` to the optimal value you determined in your plot above. Output the confusion matrix and error rate again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVAfP_iB_cZO",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "set.seed(2023)\n",
        "#INSERT CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl3pqjEA_cZO"
      },
      "source": [
        "What impact did rescaling the data have on your error rate?\n",
        "> * *Write response here*\n",
        ">\n",
        "> *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSFcQXke_cZO"
      },
      "source": [
        "**DUE:** 11:59 pm March 19, 2025\n",
        "\n",
        "**IMPORTANT** Did you collaborate with anyone on this assignment? If so, list their names here.\n",
        "> *Someone's Name*\n",
        ">\n",
        ">\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.2.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}