{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdavistr-cmu/Davis-Troller_DSPN_S25/blob/main/ex17_regularized_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xqhx0wjDoQH"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CoAxLab/Data-Explorations/blob/main/book/exercises/regularized-regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0-Q9NYTBujb"
      },
      "source": [
        "# Exercise 17: Regularized regression\n",
        "\n",
        "This homework assignment is designed to give you an intuition as an interesting property of regularization in the context of ultra-high dimensional statistical problems.\n",
        "\n",
        "You won't need to load in any data for this homework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bODln6rvBujd"
      },
      "source": [
        "---\n",
        "## 1. Simulating & visualizing data (2 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sezRLzgHBuje"
      },
      "source": [
        "We are going to be looking at what happens in the context where $p>n$. In order to have total control over our data, we will use simulations for this homework. First, we will need to load the `glmnet`, `tidyverse`, and `ggplot2` libraries for this assignment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVJwea2rBujf",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXwMchX7Bujf"
      },
      "source": [
        "We are going to generate a data set with complex structure and try to recover it using polynomial models. For simplicity sake, use the following code to produce a response variable, $y$ that has complex structure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpLho0wUde1L"
      },
      "source": [
        "*Hint: Look up what a cosine function looks like if you need a reminder.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeK03Sx7Bujg",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Generate data\n",
        "set.seed(121)\n",
        "sigma_noise = .5\n",
        "x=seq(-9,9,by=.18)\n",
        "n=length(x)\n",
        "y = 0.1*x + cos(x) + cos(x/20)+rnorm(n,sd=sigma_noise)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfmUWGIlBujg"
      },
      "source": [
        "(a) Break the data into a training set (n=50) and test set (n=51) using the `sample` function to randomly select subsets of x and y.  Make a separate data frame for the training and test data.\n",
        "\n",
        "(**Note**: *Do not* just take the first 50 observations to be the training set and last 51 observations to be the test set.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIg6XGaHBujg",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ4B7a1lBujg"
      },
      "source": [
        "(b) Plot the training data ($x$ \\& $y$). Describe the relationship that you see in the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRyRddZJBujh",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaVD7SEeBuji"
      },
      "source": [
        "How would you describe the relationship between $x$ and $y$ based on this plot?\n",
        "\n",
        "> *Write your response here*\n",
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqLPa45zBuji"
      },
      "source": [
        "---\n",
        "## 2. Bias-variance tradeoff: polynomial regression (4 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyP55tOade1P"
      },
      "source": [
        "Recall that in polynomial regression we increase model complexity by expanding $x$ out to the power $k$ (which we call degree)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxra2iFvde1Q"
      },
      "source": [
        "\n",
        "$$Y = \\hat{\\beta}_0 + \\sum_{j=1}^K \\hat{\\beta}_jX^j $$  \n",
        "\n",
        "$$ = poly(x,k)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SvSDGa9Buji"
      },
      "source": [
        "(a) Fit a 2nd degree polynomial regression model to the training data. Plot the results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vysWxHwVde1R"
      },
      "source": [
        "*Hint: Use the* `help` *function to see how to use the* `stat_smooth()` *and* `poly()` *functions.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_mZIsWwBuji",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYxz29TyBujj"
      },
      "source": [
        "How well does this 2nd degree polynomial model qualitatively fit the data? Could it do better?\n",
        "\n",
        "> *Write your response here*\n",
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A83iJUkBujj"
      },
      "source": [
        "(b) Fit a 12th degree polynomial to the data. Does this do qualitatively better or worse than the 2nd degree model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZAQ0PB5Bujj",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xanWSXvBujk"
      },
      "source": [
        "> *Write your response here*\n",
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpDFP-eSBujl"
      },
      "source": [
        "(c) Modify the loop below to estimate the bias-variance tradeoff as model complexity (i.e., degree of the polynomial model, $k$) increases from 2 to 50. Use the training data to fit the model and test data to evaluate its predictive accuracy.\n",
        "\n",
        "Visualize your results by plotting the *median* squared error for the training data and test data as a function of polynomial degree."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2kXJb-5de1S"
      },
      "source": [
        "\n",
        "(**Note**: We are using median accuracies here because there are often 1 or 2 outlier values in the higher degree polynomial models that can throw off the accuracy estimates)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnoZVv4OBujl",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Now do the variance-bias trade off analysis using regular regression\n",
        "degree = seq(2,50)\n",
        "\n",
        "# Need to setup your output vectors\n",
        "train_rss = matrix(data=NA,nrow=length(degree),ncol=1)\n",
        "test_rss = matrix(data=NA,nrow=length(degree),ncol=1)\n",
        "\n",
        "for (k in degree) {\n",
        "    # WRITE YOUR CODE HERE\n",
        "\n",
        "}\n",
        "\n",
        "# Plot your results here\n",
        "# WRITE YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx8zgVDGBujm"
      },
      "source": [
        "What do you see as $k$ increase?\n",
        "\n",
        "> *Write your response here*\n",
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfF6syENBujm"
      },
      "source": [
        "(d) Now copy the code above and let's see what happens when we go beyond $p=n$ (remember, in this case $k=p$). Test polynomial models up to $k=150$. Visualize your results by plotting the *median* squared error for the training data and test data as a function of polynomial degree.\n",
        "\n",
        "Use the `geom_vline()` function in `ggplot` to draw a vertical line where $k=n$ (here $n$ is the number of observations in the training set). This will make it clear where we cross the threshold for finding *unique* solutions in our data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fqk3xlUBBujm",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsiaI7CNBujn"
      },
      "source": [
        "What do you see as $k$ gets larger than $n$?\n",
        "\n",
        "> *Write your response here*\n",
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez8Cy8anBujn"
      },
      "source": [
        "---\n",
        "## 3. Applying regularization to the model fits (2 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFAAGungBujn"
      },
      "source": [
        "Repeat the previous bias-variance tradeoff test, going up to $k=150$, but now use ridge regression with a sparsity parameter of $\\lambda=0.00005$. Plot your results the same way as last time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uVdEguGBujn",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Now do the variance-bias trade off analysis using ridge regression\n",
        "lambda=0.00005\n",
        "degree = seq(2,150)\n",
        "\n",
        "rm(train_rss, test_rss)\n",
        "train_rss = matrix(data=NA,nrow=length(degree),ncol=1)\n",
        "test_rss = matrix(data=NA,nrow=length(degree),ncol=1)\n",
        "\n",
        "for (k in degree) {\n",
        "    # WRITE YOUR CODE HERE\n",
        "\n",
        "}\n",
        "\n",
        "# Plot your results here\n",
        "# WRITE YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IF6tO_uBujo"
      },
      "source": [
        "What happens now when $k$ gets larger than $n$?\n",
        "\n",
        "> *Write your response here*\n",
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zheO4rLBujo"
      },
      "source": [
        "---\n",
        "## 4. Reflection (2 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-65QvdnBujo"
      },
      "source": [
        "The simulations above should have shown that, when applying a regularization (i.e., a sparsity constraint), the behavior of the bias-variance tradeoff changes. Explain why this happens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkM1H1_WBujo"
      },
      "source": [
        "> *Write your response here*\n",
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ietUafKfBujo"
      },
      "source": [
        "---\n",
        "## Bonus (1 extra credit point)\n",
        "Recall that the $p=n$ threshold defines the limit for finding a *unique* solution to $Y=F(X)$ (i.e., there is only one combination of regression coefficients that is *best* at explaining variance in $Y$). With this in mind, what is regularization doing that works around this upper limit?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo5eCrpuBujp"
      },
      "source": [
        "> *Write your response here*\n",
        ">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmcAxEQCBujp"
      },
      "source": [
        "**DUE:** 5pm EST, April 10, 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYdsoRobBujp"
      },
      "source": [
        "**IMPORTANT** Did you collaborate with anyone on this assignment? If so, list their names here.\n",
        "> *Someone's Name*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.2.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}